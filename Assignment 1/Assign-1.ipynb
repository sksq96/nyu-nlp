{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyprind\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = './aclImdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard import TensorBoard\n",
    "from AdamW import AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "##### We will start by downloading IMDB Movie review dataset text dataset:\n",
    "\n",
    "```http://ai.stanford.edu/~amaas/data/sentiment/```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:59\n"
     ]
    }
   ],
   "source": [
    "labels = {'pos': 1, 'neg': 0}\n",
    "pbar = pyprind.ProgBar(50000)\n",
    "train_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "for s in ('test', 'train'):\n",
    "    for l in ('pos', 'neg'):\n",
    "        path = os.path.join(basepath, s, l)\n",
    "        for file in os.listdir(path):\n",
    "            with open(os.path.join(path, file), 'r',\n",
    "                      encoding='utf-8') as infile:\n",
    "                txt = infile.read()\n",
    "            if s == 'test':\n",
    "                train_df = train_df.append([[txt, labels[l]]], ignore_index=True)\n",
    "            elif s == 'train':\n",
    "                test_df = test_df.append([[txt, labels[l]]], ignore_index=True)\n",
    "            pbar.update()\n",
    "\n",
    "train_df.columns = ['review', 'sentiment']\n",
    "test_df.columns = ['review', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trn_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = trn_df.review.values\n",
    "train_targets = trn_df.sentiment.values\n",
    "\n",
    "val_data = val_df.review.values\n",
    "val_targets = val_df.sentiment.values\n",
    "\n",
    "test_data = test_df.review.values\n",
    "test_targets = test_df.sentiment.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is: 20000\n",
      "Val dataset size is: 5000\n",
      "Test dataset size is: 25000\n"
     ]
    }
   ],
   "source": [
    "print (\"Train dataset size is: {}\".format(train_data.shape[0]))\n",
    "print (\"Val dataset size is: {}\".format(val_data.shape[0]))\n",
    "print (\"Test dataset size is: {}\".format(test_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(r#64)<br /><br />Unredeemable, merit-less, and above all dreary trash. You know a movie is going to be bad when its sole star power is Lance Henriksen. The French title for this movie says it all: \"Inexplicable\". How can you possibly make a movie this unbelievably bad in this day and age? Whatever Jonas Quastel's trick is, it worked. This is Ã¼ber-trash, I'm talking 'Manos'-level crap, meaningless, unwatchable, not-even-so-bad-it's-good, cinematic bile of the highest order.<br /><br />Lance Henriksen IS Harlan Knowles, a character who could have been interesting if he wasn't so utterly devoid of characteristics or personality. He, along with a bunch of morons, goes on a field trip to search for an evil Sasquatch which is believed to have attacked a plane which crashed out in the woods, or something. Not much else happens. There's some soft-core (meaning: Teletubbie level) nudity and some blatant rip-offs of \"Predator\". After 92 minutes of utter pain and another ripped off scene, this time from \"Blair Witch\", the movie finally staggers across the finish line and ends. As a bonus, we only see the monster itself for about one or two scenes in the entire movie.<br /><br />There's really not much to say about this film. All you need to know is, this is a very bad movie and not even worth viewing as a \"so-bad-it's-good\" flick. \"The Untold\" is to entertainment value what Orlando Bloom is to character acting. Avoid it like arsenic.\n"
     ]
    }
   ],
   "source": [
    "# Random sample from train dataset\n",
    "import random\n",
    "print (train_data[random.randint(0, len(train_data) - 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training the classifier, first we are going to tokenize the dataset using spacy.io\n",
    "\n",
    "Run (shown in the cell below):\n",
    "\n",
    "* ```pip install spacy```\n",
    "* ```python -m spacy download en_core_web_sm```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'is', 'looking', 'at', 'buying', 'u.k.', 'startup', 'for', '1', 'billion', 'apple_is', 'is_looking', 'looking_at', 'at_buying', 'buying_u.k.', 'u.k._startup', 'startup_for', 'for_1', '1_billion']\n"
     ]
    }
   ],
   "source": [
    "# Let's write the tokenization function \n",
    "\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "tokenizer = spacy.load('en_core_web_sm')\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# lowercase and remove punctuation\n",
    "def tokenize(sent, n=2):\n",
    "    tokens = tokenizer(sent)\n",
    "    unigrams = [token.text.lower() for token in tokens if (token.text not in punctuations)]\n",
    "    ngrams = []\n",
    "    for k in range(1, n+1):\n",
    "        for i in range(len(unigrams) - k + 1):\n",
    "            ngrams.append('_'.join([unigrams[i+j] for j in range(k)]))\n",
    "    return ngrams\n",
    "\n",
    "# Example\n",
    "tokens = tokenize(u'Apple is looking at buying U.K. startup for $1 billion')\n",
    "print (tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add n-gram tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove HTML Tags, Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing val data\n",
      "Tokenizing test data\n",
      "Tokenizing train data\n"
     ]
    }
   ],
   "source": [
    "# Alternatively try running the following multi-threaded version of tokenization\n",
    "# Credit to Ilya Kulikov\n",
    "\n",
    "def tokenize_n_grams(parsed, n=1):    \n",
    "    unigrams = [token.text.lower() for token in parsed if (token.text not in punctuations)]\n",
    "    \n",
    "    # replace HTML symbols\n",
    "    unigrams = [token.replace(\"&amp;\", \"and\").replace(\"&gt;\", \">\").replace(\"&lt;\", \"<\") for token in unigrams]\n",
    "    \n",
    "    ngrams = []\n",
    "    for k in range(1, n+1):\n",
    "        for i in range(len(unigrams) - k + 1):\n",
    "            ngrams.append('_'.join([unigrams[i+j] for j in range(k)]))\n",
    "    return ngrams\n",
    "\n",
    "def tokenize_dataset(dataset, n):\n",
    "    token_dataset = []\n",
    "    # we are keeping track of all tokens in dataset\n",
    "    # in order to create vocabulary later\n",
    "    all_tokens = []\n",
    "\n",
    "    for sample in tqdm_notebook(tokenizer.pipe(dataset, disable=['parser', 'tagger', 'ner'], batch_size=512, n_threads=8)):\n",
    "        tokens = tokenize_n_grams(sample, n)\n",
    "        token_dataset.append(tokens)\n",
    "        all_tokens += tokens\n",
    "\n",
    "    return token_dataset, all_tokens\n",
    "\n",
    "\n",
    "n_gram = 2\n",
    "\n",
    "# val set tokens\n",
    "print (\"Tokenizing val data\")\n",
    "# val_data_tokens, _ = tokenize_dataset(val_data, n_gram)\n",
    "# pkl.dump(val_data_tokens, open(\"val_data_tokens.p\", \"wb\"))\n",
    "\n",
    "# test set tokens\n",
    "print (\"Tokenizing test data\")\n",
    "# test_data_tokens, _ = tokenize_dataset(test_data, n_gram)\n",
    "# pkl.dump(test_data_tokens, open(\"test_data_tokens.p\", \"wb\"))\n",
    "\n",
    "# train set tokens\n",
    "print (\"Tokenizing train data\")\n",
    "# train_data_tokens, all_train_tokens = tokenize_dataset(train_data, n_gram)\n",
    "# pkl.dump(train_data_tokens, open(\"train_data_tokens.p\", \"wb\"))\n",
    "# pkl.dump(all_train_tokens, open(\"all_train_tokens.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(val_data[0].split()), len(val_data_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n",
      "Total number of tokens in train dataset is 9390700\n"
     ]
    }
   ],
   "source": [
    "# Then, load preprocessed train, val and test datasets\n",
    "train_data_tokens = pkl.load(open(\"train_data_tokens.p\", \"rb\"))\n",
    "all_train_tokens = pkl.load(open(\"all_train_tokens.p\", \"rb\"))\n",
    "\n",
    "val_data_tokens = pkl.load(open(\"val_data_tokens.p\", \"rb\"))\n",
    "test_data_tokens = pkl.load(open(\"test_data_tokens.p\", \"rb\"))\n",
    "\n",
    "# double checking\n",
    "print (\"Train dataset size is {}\".format(len(train_data_tokens)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_tokens)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_tokens)))\n",
    "\n",
    "print (\"Total number of tokens in train dataset is {}\".format(len(all_train_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to create the vocabulary of most common 10,000 tokens in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "max_vocab_size = 10000\n",
    "# save index 0 for unk and 1 for pad\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "def build_vocab(all_tokens):\n",
    "    # Returns:\n",
    "    # id2token: list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "    # token2id: dictionary where keys represent tokens and corresponding values represent indices\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(max_vocab_size))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token\n",
    "\n",
    "token2id, id2token = build_vocab(all_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id 1818 ; token lee\n",
      "Token lee; token id 1818\n"
     ]
    }
   ],
   "source": [
    "# Lets check the dictionary by loading random token from it\n",
    "\n",
    "random_token_id = random.randint(0, len(id2token)-1)\n",
    "random_token = id2token[random_token_id]\n",
    "\n",
    "print (\"Token id {} ; token {}\".format(random_token_id, id2token[random_token_id]))\n",
    "print (\"Token {}; token id {}\".format(random_token, token2id[random_token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n"
     ]
    }
   ],
   "source": [
    "# convert token to id in the dataset\n",
    "def token2index_dataset(tokens_data):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data\n",
    "\n",
    "train_data_indices = token2index_dataset(train_data_tokens)\n",
    "val_data_indices = token2index_dataset(val_data_tokens)\n",
    "test_data_indices = token2index_dataset(test_data_tokens)\n",
    "\n",
    "# double checking\n",
    "print (\"Train dataset size is {}\".format(len(train_data_indices)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_indices)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we are going to create PyTorch DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 200\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MovieDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list, target_list):\n",
    "        \"\"\"\n",
    "        @param data_list: list of sentence tokens \n",
    "        @param target_list: list of sentence targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx = self.data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx, len(token_idx), label]\n",
    "\n",
    "def sent_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "    #print(\"collate batch: \", batch[0][0])\n",
    "    #batch[0][0] = batch[0][0][:MAX_SENTENCE_LENGTH]\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_vec)\n",
    "    return [torch.from_numpy(np.array(data_list)), torch.LongTensor(length_list), torch.LongTensor(label_list)]\n",
    "\n",
    "# create pytorch dataloader\n",
    "#train_loader = MovieDataset(train_data_indices, train_targets)\n",
    "#val_loader = MovieDataset(val_data_indices, val_targets)\n",
    "#test_loader = MovieDataset(test_data_indices, test_targets)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = MovieDataset(train_data_indices, train_targets)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=sent_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = MovieDataset(val_data_indices, val_targets)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=sent_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset = MovieDataset(test_data_indices, test_targets)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=sent_collate_func,\n",
    "                                           shuffle=False)\n",
    "\n",
    "# for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "#     print (data)\n",
    "#     print (labels)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will define Bag-of-N-Grams model in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import torch related libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BagOfNGrams(nn.Module):\n",
    "    \"\"\"\n",
    "    BagOfNGrams classification model\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, emb_dim):\n",
    "        \"\"\"\n",
    "        @param vocab_size: size of the vocabulary. \n",
    "        @param emb_dim: size of the word embedding\n",
    "        \"\"\"\n",
    "        super(BagOfNGrams, self).__init__()\n",
    "        # pay attention to padding_idx \n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.linear = nn.Linear(emb_dim, 2)\n",
    "    \n",
    "    def forward(self, data, length):\n",
    "        \"\"\"\n",
    "        \n",
    "        @param data: matrix of size (batch_size, max_sentence_length). Each row in data represents a \n",
    "            review that is represented using n-gram index. Note that they are padded to have same length.\n",
    "        @param length: an int tensor of size (batch_size), which represents the non-trivial (excludes padding)\n",
    "            length of each sentences in the data.\n",
    "        \"\"\"\n",
    "        out = self.embed(data)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        out /= length.view(length.size()[0],1).expand_as(out).float()\n",
    "     \n",
    "        # return logits\n",
    "        out = self.linear(out.float())\n",
    "        return out\n",
    "\n",
    "emb_dim = 100\n",
    "model = BagOfNGrams(len(id2token), emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BagOfNGrams(\n",
       "  (embed): Embedding(10002, 100, padding_idx=0)\n",
       "  (linear): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Step: [1/625], Validation Acc: 49.5, Loss: 0.6826670169830322\n",
      "Epoch: [1/10], Step: [101/625], Validation Acc: 55.88, Loss: 0.6843814849853516\n",
      "Epoch: [1/10], Step: [201/625], Validation Acc: 67.32, Loss: 0.6269193887710571\n",
      "Epoch: [1/10], Step: [301/625], Validation Acc: 70.82, Loss: 0.6119614243507385\n",
      "Epoch: [1/10], Step: [401/625], Validation Acc: 73.66, Loss: 0.5884591341018677\n",
      "Epoch: [1/10], Step: [501/625], Validation Acc: 75.26, Loss: 0.5575915575027466\n",
      "Epoch: [1/10], Step: [601/625], Validation Acc: 78.02, Loss: 0.47119784355163574\n",
      "Epoch: [2/10], Step: [1/625], Validation Acc: 78.4, Loss: 0.4938708245754242\n",
      "Epoch: [2/10], Step: [101/625], Validation Acc: 79.52, Loss: 0.49663034081459045\n",
      "Epoch: [2/10], Step: [201/625], Validation Acc: 80.56, Loss: 0.46275240182876587\n",
      "Epoch: [2/10], Step: [301/625], Validation Acc: 81.68, Loss: 0.36143258213996887\n",
      "Epoch: [2/10], Step: [401/625], Validation Acc: 82.4, Loss: 0.561408519744873\n",
      "Epoch: [2/10], Step: [501/625], Validation Acc: 83.34, Loss: 0.3795948326587677\n",
      "Epoch: [2/10], Step: [601/625], Validation Acc: 83.38, Loss: 0.42019277811050415\n",
      "Epoch: [3/10], Step: [1/625], Validation Acc: 83.74, Loss: 0.3463396728038788\n",
      "Epoch: [3/10], Step: [101/625], Validation Acc: 83.68, Loss: 0.3621046245098114\n",
      "Epoch: [3/10], Step: [201/625], Validation Acc: 84.22, Loss: 0.5127233266830444\n",
      "Epoch: [3/10], Step: [301/625], Validation Acc: 84.48, Loss: 0.3149031400680542\n",
      "Epoch: [3/10], Step: [401/625], Validation Acc: 84.7, Loss: 0.3136371672153473\n",
      "Epoch: [3/10], Step: [501/625], Validation Acc: 84.86, Loss: 0.332241415977478\n",
      "Epoch: [3/10], Step: [601/625], Validation Acc: 85.06, Loss: 0.36419540643692017\n",
      "Epoch: [4/10], Step: [1/625], Validation Acc: 84.92, Loss: 0.36719876527786255\n",
      "Epoch: [4/10], Step: [101/625], Validation Acc: 85.04, Loss: 0.188815176486969\n",
      "Epoch: [4/10], Step: [201/625], Validation Acc: 85.42, Loss: 0.3015788197517395\n",
      "Epoch: [4/10], Step: [301/625], Validation Acc: 85.54, Loss: 0.36827656626701355\n",
      "Epoch: [4/10], Step: [401/625], Validation Acc: 85.74, Loss: 0.3593989610671997\n",
      "Epoch: [4/10], Step: [501/625], Validation Acc: 85.9, Loss: 0.3125634491443634\n",
      "Epoch: [4/10], Step: [601/625], Validation Acc: 85.94, Loss: 0.2951067090034485\n",
      "Epoch: [5/10], Step: [1/625], Validation Acc: 85.76, Loss: 0.3107774257659912\n",
      "Epoch: [5/10], Step: [101/625], Validation Acc: 86.06, Loss: 0.20952394604682922\n",
      "Epoch: [5/10], Step: [201/625], Validation Acc: 86.36, Loss: 0.12096449732780457\n",
      "Epoch: [5/10], Step: [301/625], Validation Acc: 86.36, Loss: 0.3498322665691376\n",
      "Epoch: [5/10], Step: [401/625], Validation Acc: 86.5, Loss: 0.2573566436767578\n",
      "Epoch: [5/10], Step: [501/625], Validation Acc: 86.44, Loss: 0.22707535326480865\n",
      "Epoch: [5/10], Step: [601/625], Validation Acc: 86.26, Loss: 0.15256978571414948\n",
      "Epoch: [6/10], Step: [1/625], Validation Acc: 86.58, Loss: 0.23324599862098694\n",
      "Epoch: [6/10], Step: [101/625], Validation Acc: 86.58, Loss: 0.2526828348636627\n",
      "Epoch: [6/10], Step: [201/625], Validation Acc: 86.7, Loss: 0.13939322531223297\n",
      "Epoch: [6/10], Step: [301/625], Validation Acc: 86.76, Loss: 0.1456526666879654\n",
      "Epoch: [6/10], Step: [401/625], Validation Acc: 86.64, Loss: 0.2114487588405609\n",
      "Epoch: [6/10], Step: [501/625], Validation Acc: 87.02, Loss: 0.1671784222126007\n",
      "Epoch: [6/10], Step: [601/625], Validation Acc: 86.76, Loss: 0.2248847931623459\n",
      "Epoch: [7/10], Step: [1/625], Validation Acc: 86.34, Loss: 0.29779624938964844\n",
      "Epoch: [7/10], Step: [101/625], Validation Acc: 86.58, Loss: 0.1265786588191986\n",
      "Epoch: [7/10], Step: [201/625], Validation Acc: 86.62, Loss: 0.1213253065943718\n",
      "Epoch: [7/10], Step: [301/625], Validation Acc: 86.42, Loss: 0.14820829033851624\n",
      "Epoch: [7/10], Step: [401/625], Validation Acc: 86.44, Loss: 0.14424626529216766\n",
      "Epoch: [7/10], Step: [501/625], Validation Acc: 86.68, Loss: 0.10118724405765533\n",
      "Epoch: [7/10], Step: [601/625], Validation Acc: 86.7, Loss: 0.17217868566513062\n",
      "Epoch: [8/10], Step: [1/625], Validation Acc: 86.26, Loss: 0.1876293122768402\n",
      "Epoch: [8/10], Step: [101/625], Validation Acc: 86.56, Loss: 0.18722572922706604\n",
      "Epoch: [8/10], Step: [201/625], Validation Acc: 86.9, Loss: 0.2357761710882187\n",
      "Epoch: [8/10], Step: [301/625], Validation Acc: 87.06, Loss: 0.2192988395690918\n",
      "Epoch: [8/10], Step: [401/625], Validation Acc: 86.46, Loss: 0.1994297206401825\n",
      "Epoch: [8/10], Step: [501/625], Validation Acc: 86.94, Loss: 0.11834670603275299\n",
      "Epoch: [8/10], Step: [601/625], Validation Acc: 86.74, Loss: 0.06889279186725616\n",
      "Epoch: [9/10], Step: [1/625], Validation Acc: 86.82, Loss: 0.19558775424957275\n",
      "Epoch: [9/10], Step: [101/625], Validation Acc: 86.48, Loss: 0.12804993987083435\n",
      "Epoch: [9/10], Step: [201/625], Validation Acc: 86.9, Loss: 0.159028559923172\n",
      "Epoch: [9/10], Step: [301/625], Validation Acc: 86.9, Loss: 0.21480797231197357\n",
      "Epoch: [9/10], Step: [401/625], Validation Acc: 86.94, Loss: 0.12184056639671326\n",
      "Epoch: [9/10], Step: [501/625], Validation Acc: 86.96, Loss: 0.056069862097501755\n",
      "Epoch: [9/10], Step: [601/625], Validation Acc: 86.62, Loss: 0.2452109307050705\n",
      "Epoch: [10/10], Step: [1/625], Validation Acc: 86.86, Loss: 0.2098616659641266\n",
      "Epoch: [10/10], Step: [101/625], Validation Acc: 86.4, Loss: 0.23501016199588776\n",
      "Epoch: [10/10], Step: [201/625], Validation Acc: 85.96, Loss: 0.12944525480270386\n",
      "Epoch: [10/10], Step: [301/625], Validation Acc: 86.4, Loss: 0.11470672488212585\n",
      "Epoch: [10/10], Step: [401/625], Validation Acc: 86.76, Loss: 0.2380826473236084\n",
      "Epoch: [10/10], Step: [501/625], Validation Acc: 86.62, Loss: 0.44440117478370667\n",
      "Epoch: [10/10], Step: [601/625], Validation Acc: 86.8, Loss: 0.08823442459106445\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 10 # number epoch to train\n",
    "\n",
    "# Criterion and Optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "model_dir = f\"runs/n/{1}/{time.asctime(time.localtime())}/\"\n",
    "tb = TensorBoard(model_dir)\n",
    "\n",
    "# Function for testing the model\n",
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for data, lengths, labels in loader:\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)\n",
    "\n",
    "step = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data_batch, length_batch)\n",
    "        loss = criterion(outputs, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # validate every 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            # validate\n",
    "            val_acc = test_model(val_loader, model)\n",
    "            print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}, Loss: {}'.format( \n",
    "                       epoch+1, num_epochs, i+1, len(train_loader), val_acc, loss.item()))\n",
    "            \n",
    "            if tb is not None:\n",
    "                tb.scalar_summary(\"metric/loss\", loss.item(), step)\n",
    "                tb.scalar_summary(\"metric/val_acc\", val_acc, step)\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training for 10 epochs\n",
      "Val Acc 86.44\n",
      "Test Acc 85.216\n"
     ]
    }
   ],
   "source": [
    "print (\"After training for {} epochs\".format(num_epochs))\n",
    "print (\"Val Acc {}\".format(test_model(val_loader, model)))\n",
    "print (\"Test Acc {}\".format(test_model(test_loader, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correct  Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0, True: 0\n",
      "I can't believe this movie has an average rating of 7.0! It is a fiendishly bad movie, and I saw it when it was fairly new, and I was in the age group that is supposed to like it!\n",
      "\n",
      "\n",
      "Predicted: 1, True: 1\n",
      "Wonderful movie. Adult content. Lots of erotic scenes plus excellent music and dance scenes. My wife and I absolutely loved this movie and wish they'd make more like it.\n",
      "\n",
      "\n",
      "Predicted: 0, True: 0\n",
      "I thought this movie was horrible. I was bored and had to use all the self control I have to not scream at the screen. Mod Squad was beyond cheesy, beyond cliche, and utterly predictable.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_dataset = MovieDataset(val_data_indices, val_targets)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=sent_collate_func,\n",
    "                                           shuffle=False)\n",
    "\n",
    "step = 0\n",
    "for index, (data, lengths, labels) in enumerate(val_loader):\n",
    "    data_batch, length_batch, label_batch = data, lengths, labels\n",
    "    outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
    "    predicted = outputs.max(1, keepdim=True)[1]\n",
    "    \n",
    "    predicted_list = predicted.eq(labels.view_as(predicted)).squeeze(1).tolist()\n",
    "\n",
    "    for idx, value in enumerate(predicted_list):\n",
    "        if value == 1:\n",
    "            if len(val_data[idx + index*BATCH_SIZE]) < 200:\n",
    "                print(f\"Predicted: {predicted[idx].item()}, True: {labels[idx].item()}\")\n",
    "                print(val_data[idx + index*BATCH_SIZE], end='\\n\\n\\n')\n",
    "                step += 1\n",
    "        \n",
    "        if step >= 10:\n",
    "            break\n",
    "    \n",
    "    if step >= 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Incorrect Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0, True: 1\n",
      "In my opinion, this film has wonderful lighting and even better photography. Too bad the story is not all that good and Mr. Cage sometimes loses his accent. But two thumbs up for lighting and the DP!\n",
      "\n",
      "\n",
      "Predicted: 0, True: 1\n",
      "I don't care if some people voted this movie to be bad. If you want the Truth this is a Very Good Movie! It has every thing a movie should have. You really should Get this one.\n",
      "\n",
      "\n",
      "Predicted: 1, True: 0\n",
      "My first thoughts on this film were of using science fiction as a bad way to show naked women, althought not a brilliant story line it had quite a good ending\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_dataset = MovieDataset(val_data_indices, val_targets)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=sent_collate_func,\n",
    "                                           shuffle=False)\n",
    "\n",
    "step = 0\n",
    "for index, (data, lengths, labels) in enumerate(val_loader):\n",
    "    data_batch, length_batch, label_batch = data, lengths, labels\n",
    "    outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
    "    predicted = outputs.max(1, keepdim=True)[1]\n",
    "    \n",
    "    predicted_list = predicted.eq(labels.view_as(predicted)).squeeze(1).tolist()\n",
    "\n",
    "    for idx, value in enumerate(predicted_list):\n",
    "        if value == 0:\n",
    "            if len(val_data[idx + index*BATCH_SIZE]) < 200:\n",
    "                print(f\"Predicted: {predicted[idx].item()}, True: {labels[idx].item()}\")\n",
    "                print(val_data[idx + index*BATCH_SIZE], end='\\n\\n\\n')\n",
    "                step += 1\n",
    "        \n",
    "        if step >= 10:\n",
    "            break\n",
    "    \n",
    "    if step >= 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
